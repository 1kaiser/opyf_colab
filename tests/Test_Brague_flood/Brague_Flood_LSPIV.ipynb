{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brague River Flood LSPIV Analysis ðŸŒŠ
",
    "
",
    "This notebook demonstrates Large-Scale Particle Image Velocimetry (LSPIV) using `opyflow` on amateur videos of the November 2019 flood of the Brague river at Biot, France.
",
    "
",
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opyflow opencv-python matplotlib numpy
",
    "import os, sys
",
    "import cv2
",
    "import numpy as np
",
    "import matplotlib.pyplot as plt
",
    "import opyf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Data
",
    "We download the raw MOV videos from the original research dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O IMG_1139.MOV "https://www.dropbox.com/s/npe8srzxls6rav1/IMG_1139.MOV?dl=1"
",
    "!wget -O IMG_1142.MOV "https://www.dropbox.com/s/bq4ed5hsycuqxjk/IMG_1142.MOV?dl=1""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stabilization
",
    "Amateur videos often suffer from camera shake. We use a mask to identify static zones (trees, houses) to calculate stabilization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = opyf.videoAnalyzer('IMG_1139.MOV')
",
    "video.set_vecTime(Ntot=25, starting_frame=200)
",
    "video.set_interpolationParams(Sharpness=2)
",
    "video.set_goodFeaturesToTrackParams(qualityLevel=0.01)
",
    "
",
    "# Load stabilization mask
",
    "mask = cv2.imread('1139/mask_1139.png')
",
    "A = mask > 100
",
    "video.set_stabilization(mask=A[:,:,0], mute=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Orthorectification (Bird's Eye View)
",
    "Transforming image coordinates to real-world metric coordinates using Ground Control Points (GCPs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Xpx,Ypx) points
",
    "image_points = np.array([
",
    "    (355, 429),  # left 
",
    "    (1338, 350), # right
",
    "    (99, 562),   # left front bank
",
    "    (1673, 364),  # right front bank
",
    "], dtype="double")
",
    "
",
    "# (XYZ) coordinates
",
    "model_points = np.array([
",
    "    (30.13, -8.28, 0),   # left 
",
    "    (32.88, -28.08, 0),  # right bank
",
    "    (20.46, -4.47, 0.4), # left front bank
",
    "    (21.32, -27.14, 0.4),# right front bank
",
    "], dtype="double")
",
    "
",
    "model_points = model_points - model_points[0]
",
    "
",
    "video.set_birdEyeViewProcessing(image_points,
",
    "                                model_points, [-12, 4, -32.],
",
    "                                rotation=np.array([[1., 0, 0],[0,-1,0],[0,0,-1.]]),
",
    "                                scale=True, framesPerSecond=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run velocimetry
",
    "Calculate the surface velocity fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.set_vlim([0, 10])
",
    "video.extractGoodFeaturesDisplacementsAccumulateAndInterpolate(display1='quiver', display2='field', displayColor=True)
",
    "video.set_filtersParams(maxDevInRadius=1.5, RadiusF=0.15, range_Vx=[0.01, 10])
",
    "video.filterAndInterpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒŸ Future Integration: JAX Vision Models
",
    "In this `opyf_colab` ecosystem, we can enhance this traditional LSPIV workflow using JAX:
",
    "
",
    "### 1. **LightGlue for Stabilization**
",
    "Instead of manual masking, use **LightGlue JAX** to find thousands of robust correspondences on static background elements between frames. This provides sub-pixel stabilization even in low-light or blurry conditions.
",
    "
",
    "### 2. **Depth Pro for Orthorectification**
",
    "Use **Depth Pro JAX** to estimate the metric depth of the water surface. This can replace or supplement GCPs, allowing for automatic bird's eye view transformations in unmapped locations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
